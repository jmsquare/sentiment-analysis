{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1CS0mREa6da",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVlWMnxFMslK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# What is sentiment analysis? ü§î\n",
    "Sentiment Analysis is the technique of determining the sentiments involved in the given text. The most prominent sentiments involved are 'Positive', 'Neutral' or 'Negative'. \n",
    "\n",
    "# Why is Sentiment Analysis important? üîñ\n",
    "Sentiment Analysis helps you understand your customers better.\n",
    "Imagine you have released a product and want to monitor the performance of your product based on the reviews and feedbacks or even the twitter posts about the product. The right understanding of user feedback and sentiment will help you improve your product and it's reach.\n",
    "\n",
    "## Lets build a sentiment analysis model üë∑‚Äç‚ôÄÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXmFWRmnW5Rz",
    "outputId": "79a2893a-a32c-447d-d6ae-ea7dee7a8fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 01:24:14,390 pid:212 ThreadPoolExecutor-0_4 giskard.ml_worker.core.model INFO     Casting dataframe columns from {'text': 'object'} to {'text': 'object'}\n",
      "2022-11-10 01:24:14,404 pid:212 ThreadPoolExecutor-0_4 giskard.ml_worker.utils.logging INFO     Predicted dataset with shape (1, 1) executed in 0:00:00.014527\n",
      "2022-11-10 01:24:17,063 pid:212 ThreadPoolExecutor-0_3 giskard.ml_worker.server.ml_worker_service INFO     File already exists: /root/giskard-home/projects/sentiment_analysis_jm_bis/models/model_7675.zst\n",
      "2022-11-10 01:24:17,891 pid:212 ThreadPoolExecutor-0_6 giskard.ml_worker.utils.logging INFO     giskard.ml_worker.utils.grpc_mapper.deserialize_model executed in 0:00:00.707597\n",
      "2022-11-10 01:24:17,893 pid:212 ThreadPoolExecutor-0_6 giskard.ml_worker.core.model INFO     Casting dataframe columns from {'text': 'object'} to {'text': 'object'}\n",
      "2022-11-10 01:24:17,908 pid:212 ThreadPoolExecutor-0_6 giskard.ml_worker.utils.logging INFO     Predicted dataset with shape (1, 1) executed in 0:00:00.016069\n",
      "2022-11-10 01:24:19,773 pid:212 ThreadPoolExecutor-0_2 giskard.ml_worker.server.ml_worker_service INFO     File already exists: /root/giskard-home/projects/sentiment_analysis_jm_bis/models/model_7675.zst\n",
      "2022-11-10 01:24:20,581 pid:212 ThreadPoolExecutor-0_8 giskard.ml_worker.utils.logging INFO     giskard.ml_worker.utils.grpc_mapper.deserialize_model executed in 0:00:00.699796\n",
      "2022-11-10 01:24:20,582 pid:212 ThreadPoolExecutor-0_8 giskard.ml_worker.core.model INFO     Casting dataframe columns from {'text': 'object'} to {'text': 'object'}\n",
      "2022-11-10 01:24:20,595 pid:212 ThreadPoolExecutor-0_8 giskard.ml_worker.utils.logging INFO     Predicted dataset with shape (1, 1) executed in 0:00:00.013639\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tail -f /root/giskard-home/run/ml-worker.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jmjm/PycharmProjects/sentiment-analysis'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/jmjm/PycharmProjects/sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path is a list of absolute path strings\n",
    "sys.path.append('/Users/jmjm/PycharmProjects/sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\r\n",
      "  python3    /Users/jmjm/PycharmProjects/sentiment-analysis/venv/share/jupyter/kernels/python3\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      " \"argv\": [\r\n",
      "  \"/Users/jmjm/PycharmProjects/sentiment-analysis/venv/bin/python3\",\r\n",
      "  \"-m\",\r\n",
      "  \"ipykernel_launcher\",\r\n",
      "  \"-f\",\r\n",
      "  \"{connection_file}\"\r\n",
      " ],\r\n",
      " \"display_name\": \"Python 3 (ipykernel)\",\r\n",
      " \"language\": \"python\",\r\n",
      " \"metadata\": {\r\n",
      "  \"debugger\": true\r\n",
      " }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat /Users/jmjm/PycharmProjects/sentiment-analysis/venv/share/jupyter/kernels/python3/kernel.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.8.3\r\n",
      "aiosignal==1.3.1\r\n",
      "anyio==3.6.2\r\n",
      "appnope==0.1.3\r\n",
      "argon2-cffi==21.3.0\r\n",
      "argon2-cffi-bindings==21.2.0\r\n",
      "asttokens==2.1.0\r\n",
      "async-timeout==4.0.2\r\n",
      "attrs==22.1.0\r\n",
      "backcall==0.2.0\r\n",
      "beautifulsoup4==4.11.1\r\n",
      "bleach==5.0.1\r\n",
      "certifi==2022.9.24\r\n",
      "cffi==1.15.1\r\n",
      "charset-normalizer==2.1.1\r\n",
      "click==8.1.3\r\n",
      "cloudpickle==2.2.0\r\n",
      "datasets==2.6.1\r\n",
      "debugpy==1.6.3\r\n",
      "decorator==5.1.1\r\n",
      "defusedxml==0.7.1\r\n",
      "dill==0.3.5.1\r\n",
      "docutils==0.19\r\n",
      "eli5==0.13.0\r\n",
      "entrypoints==0.4\r\n",
      "executing==1.2.0\r\n",
      "fastjsonschema==2.16.2\r\n",
      "filelock==3.8.0\r\n",
      "frozenlist==1.3.3\r\n",
      "fsspec==2022.11.0\r\n",
      "giskard @ file:///tmp/giskard-1.7.0a7.dev20221110233700-py3-none-any.whl\r\n",
      "googleapis-common-protos==1.56.4\r\n",
      "graphviz==0.20.1\r\n",
      "grpcio==1.50.0\r\n",
      "grpcio-status==1.48.2\r\n",
      "huggingface-hub==0.10.1\r\n",
      "idna==3.4\r\n",
      "importlib-metadata==4.13.0\r\n",
      "ipykernel==6.17.1\r\n",
      "ipython==8.6.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==8.0.2\r\n",
      "jedi==0.18.1\r\n",
      "Jinja2==3.1.2\r\n",
      "joblib==1.2.0\r\n",
      "jsonschema==4.17.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-console==6.4.4\r\n",
      "jupyter-server==1.23.1\r\n",
      "jupyter_client==7.4.5\r\n",
      "jupyter_core==5.0.0\r\n",
      "jupyterlab-pygments==0.2.2\r\n",
      "jupyterlab-widgets==3.0.3\r\n",
      "llvmlite==0.39.1\r\n",
      "lockfile==0.12.2\r\n",
      "MarkupSafe==2.1.1\r\n",
      "matplotlib-inline==0.1.6\r\n",
      "mistune==2.0.4\r\n",
      "mixpanel==4.10.0\r\n",
      "multidict==6.0.2\r\n",
      "multiprocess==0.70.13\r\n",
      "nbclassic==0.4.8\r\n",
      "nbclient==0.7.0\r\n",
      "nbconvert==7.2.4\r\n",
      "nbformat==5.7.0\r\n",
      "nest-asyncio==1.5.6\r\n",
      "notebook==6.5.2\r\n",
      "notebook_shim==0.2.2\r\n",
      "numba==0.56.4\r\n",
      "numpy==1.21.6\r\n",
      "oauthlib==3.2.2\r\n",
      "packaging==21.3\r\n",
      "pandas==1.5.1\r\n",
      "pandocfilters==1.5.0\r\n",
      "parso==0.8.3\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "platformdirs==2.5.3\r\n",
      "prometheus-client==0.15.0\r\n",
      "prompt-toolkit==3.0.32\r\n",
      "protobuf==3.20.3\r\n",
      "psutil==5.9.4\r\n",
      "ptyprocess==0.7.0\r\n",
      "pure-eval==0.2.2\r\n",
      "pyarrow==10.0.0\r\n",
      "pycparser==2.21\r\n",
      "pydantic==1.10.2\r\n",
      "Pygments==2.13.0\r\n",
      "pyparsing==3.0.9\r\n",
      "pyrsistent==0.19.2\r\n",
      "python-daemon==2.3.2\r\n",
      "python-dateutil==2.8.2\r\n",
      "pytz==2022.6\r\n",
      "PyYAML==6.0\r\n",
      "pyzmq==24.0.1\r\n",
      "qtconsole==5.4.0\r\n",
      "QtPy==2.3.0\r\n",
      "regex==2022.10.31\r\n",
      "requests==2.28.1\r\n",
      "requests-oauthlib==1.3.1\r\n",
      "requests-toolbelt==0.9.1\r\n",
      "responses==0.18.0\r\n",
      "scikit-learn==1.0.2\r\n",
      "scipy==1.7.3\r\n",
      "Send2Trash==1.8.0\r\n",
      "shap==0.41.0\r\n",
      "six==1.16.0\r\n",
      "slicer==0.0.7\r\n",
      "sniffio==1.3.0\r\n",
      "soupsieve==2.3.2.post1\r\n",
      "stack-data==0.6.0\r\n",
      "tabulate==0.9.0\r\n",
      "tenacity==8.1.0\r\n",
      "terminado==0.17.0\r\n",
      "threadpoolctl==3.1.0\r\n",
      "tinycss2==1.2.1\r\n",
      "tokenizers==0.13.2\r\n",
      "tornado==6.2\r\n",
      "tqdm==4.64.1\r\n",
      "traitlets==5.5.0\r\n",
      "transformers==4.24.0\r\n",
      "tweepy==4.12.1\r\n",
      "typing_extensions==4.4.0\r\n",
      "urllib3==1.26.12\r\n",
      "wcwidth==0.2.5\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client==1.4.2\r\n",
      "widgetsnbextension==4.0.3\r\n",
      "xxhash==3.1.0\r\n",
      "yarl==1.8.1\r\n",
      "zipp==3.10.0\r\n",
      "zstandard==0.15.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jmjm/PycharmProjects/sentiment-analysis/venv/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liZwiUwH5y2I",
    "outputId": "e497bbd0-e38d-4a31-de4c-a38aab1bbb51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 02:17:28,075 pid:11445 MainThread giskard.cli  INFO     Starting ML Worker client daemon\r\n",
      "2022-11-12 02:17:28,077 pid:11445 MainThread giskard.cli  WARNING  Another ML Worker client for dev.giskard.ai:40051 is already running with PID: 10053. Not starting a new one.\r\n"
     ]
    }
   ],
   "source": [
    "!giskard worker start -d -h dev.giskard.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULaaNB51fZkn",
    "outputId": "88bf33c8-fc00-465b-c35b-1761cd029616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-07 23:46:10,286 pid:544 MainThread giskard.cli  INFO     Stopped ML Worker Daemon by PID: 218\n"
     ]
    }
   ],
   "source": [
    "!giskard worker stop -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.9/site-packages (6.17.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.9/site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: appnope in ./venv/lib/python3.9/site-packages (from ipykernel) (0.1.3)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.9/site-packages (from ipykernel) (5.9.4)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.9/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in ./venv/lib/python3.9/site-packages (from ipykernel) (1.6.3)\n",
      "Requirement already satisfied: tornado>=6.1 in ./venv/lib/python3.9/site-packages (from ipykernel) (6.2)\n",
      "Requirement already satisfied: pyzmq>=17 in ./venv/lib/python3.9/site-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.9/site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel) (5.5.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from ipykernel) (21.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.9/site-packages (from ipykernel) (7.4.5)\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.32)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.13.0)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.0)\n",
      "Requirement already satisfied: entrypoints in ./venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in ./venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.9/site-packages (from packaging->ipykernel) (3.0.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.9/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel) (2.5.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Installed kernelspec python3 in /Users/jmjm/Library/Jupyter/kernels/python3\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "XA0apbYgxWgg",
    "outputId": "4f0f6ae4-0c49-4263-b6d6-ebd0af6d8bd8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
       "0           0  570306133677760513           neutral   \n",
       "1           1  570301130888122368          positive   \n",
       "2           2  570301083672813571           neutral   \n",
       "3           3  570301031407624196          negative   \n",
       "4           4  570300817074462722          negative   \n",
       "\n",
       "   airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
       "0                        1.0000            NaN                        NaN   \n",
       "1                        0.3486            NaN                     0.0000   \n",
       "2                        0.6837            NaN                        NaN   \n",
       "3                        1.0000     Bad Flight                     0.7033   \n",
       "4                        1.0000     Can't Tell                     1.0000   \n",
       "\n",
       "          airline airline_sentiment_gold        name negativereason_gold  \\\n",
       "0  Virgin America                    NaN     cairdin                 NaN   \n",
       "1  Virgin America                    NaN    jnardino                 NaN   \n",
       "2  Virgin America                    NaN  yvonnalynn                 NaN   \n",
       "3  Virgin America                    NaN    jnardino                 NaN   \n",
       "4  Virgin America                    NaN    jnardino                 NaN   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                @VirginAmerica What @dhepburn said.   \n",
       "1              0  @VirginAmerica plus you've added commercials t...   \n",
       "2              0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3              0  @VirginAmerica it's really aggressive to blast...   \n",
       "4              0  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tweepy\n",
    "\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/twitter_us_airline_sentiment_analysis.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "# Lets see how our data looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JsRR0NbFq_y7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "# Replace the Username with @user and the URL in the tweet with http for better comprehension of data for the model\n",
    "def preprocess(text):\n",
    "    text = \" \".join(text.split())\n",
    "    text = re.sub(r'http\\S+', 'http', text) \n",
    "    text = re.sub(r'@\\S+', '@user', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "a6702f313e0444648237775fa7e75f0e",
      "1997813f378f49babcfc2e4fd8d9bffa",
      "cf9f715ad5ef4cadab2d7a1e42eeb5fd",
      "2e2d886843104af48b43e60e08f2eaca",
      "91847cc3840f4c719d8c2df8a2f02d58",
      "06d946f52b854886bb87e6dec2d3de33",
      "7eb657a3d2534928a1ec9d65eeede7a7",
      "9d82a182865e458c86a84890fc3fdd6c",
      "6296e3ef24c74862820a08e26a68300f",
      "8c0c92a04f42431c979b63cf1639c39b",
      "b1524520f4084d24a0a7b6740412aaf4",
      "cb9440d378f14d17a622118a2ce6463a",
      "92807e26f48541f19d3a96d4cc902057",
      "b256a26d6be741b894351ef9767b3f8c",
      "958f20afe0974f6b935edaf21812db9c",
      "05431caf64ec45578e7bebcfbf8793e9",
      "4b3dbb16958b436b87062cfcd8449e7f",
      "b9bc25db3b0044d8ba47d91fb002bcb4",
      "20bf1250145b4035a26f0abaeb8ad397",
      "5b3f6395ccce4ebe93d152cad2590ae1",
      "e5b6ecd5eea743a2a3b51758358bddb4",
      "f9e58cc62392447bbb6e18c8d717ce68",
      "cc352732f21d4a43a03b18a2bf416586",
      "71bc594634b24dddb7e13958eed0f8c9",
      "5af3e3f57dc54a75a96c9cbd0a43d6d0",
      "57cfdccea7104655894840e76dd19cf8",
      "dc4ca8b791bc49d6a7d7c033b7122a22",
      "db451d50371f40ff94d8815b197f9e66",
      "663b2a0bcb664c49acbca8b75846f968",
      "1378411b913f4543bf18f49982d1f257",
      "95fd39e854ec485c83445fdc79b0ec78",
      "babe7ddacc7e41bb9e8a491c2dace6df",
      "aa64b2c6ed1940e29db9cb6ac282c1ca",
      "77070a12337f4f31ae419f0c5d576ab9",
      "8633c5f48eae42bea49f585a2efbf63e",
      "5a65d70f73f24e45bccad44111560965",
      "77c3c230ae14453981e2c12669abc6e4",
      "c1857a9f64de4bb283cb4dc98da3a36a",
      "dca1c643f5ef4d2c8b634483308d22a6",
      "b356bbd1a04e496bb35baa52216a0a7c",
      "f4f8931b838f42e69c583cba079d8819",
      "5e2963e445e04d7c976b5c8280be9409",
      "f31d095b9838490f887e3d085fac6fbc",
      "205c9112e6ec4393baf11cbb19197cea",
      "6f7c4695785e4627b8f9c2fce9c124b6",
      "c7543528284d48778f19e198879d6c3e",
      "30bf10b8b69444e0bdeb69a150bff90d",
      "9dd398a3b1bb45319c6b267d79f9fc3c",
      "ef0d1af1abdc4184b62910289307e388",
      "619170c0b67545639fc79008be836570",
      "eb4de1afc71d4a7694d1cb590736f439",
      "597ef6c3d5714ba9b17c4b5e0c4e6298",
      "94841079aae14290a54e755305e1fe98",
      "2c638db378e940be8ac9a881f3e5bcab",
      "cac1d8002367468ca4a0099ca561396d",
      "662239855e124b55864dca725d48fe51",
      "5bbb2b62a064459da41036486d8467b6",
      "9816bf8f2728475189e8119064e681d8",
      "f7e9822b18fb461aab94545a9f782cf4",
      "370d3a9c8c9b46ba9cc7a18d3247e4b5",
      "dd2ef87554ee4ad5931c99eb348cb6d8",
      "240fbc1a408a44e6b0f4ba741d4b3877",
      "433494e2cec941ca948d534f0801ccfd",
      "68c8d063693a456fb4aebe5c05acbc42",
      "cbfd1bdb36aa4606995f4b7e4dc49b48",
      "eaa558d36243448aa3f8dd9a815285bf"
     ]
    },
    "id": "5oseyfAwQTdr",
    "outputId": "f099feae-4ce0-4651-a73d-437fe8b21603",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"Souvikcmsa/SentimentAnalysisDistillBERT\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"max_length\": 64,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padding\": \"max_length\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/jmjm/.cache/huggingface/hub/models--Souvikcmsa--SentimentAnalysisDistillBERT/snapshots/f4f1eed70d9b2446020173ee7ae4b05c68048cbd/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Souvikcmsa/SentimentAnalysisDistillBERT.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "\n",
    "# Define pretrained tokenizer and model\n",
    "model_name = \"Souvikcmsa/SentimentAnalysisDistillBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "xXl-wgTteGf1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the evaluation metrics \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    pred, labels = eval_pred\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4dCBYAatnRe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lets train the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K0lrMmqvfGNq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# ----- 1. Preprocess data -----#\n",
    "# Preprocess data\n",
    "\n",
    "X = list(data[\"text\"].apply(preprocess))\n",
    "classification_labels_mapping = {'negative': 0,'neutral': 1, 'positive':2}\n",
    "y = list(data['airline_sentiment'].map(classification_labels_mapping)) # Converting target labels to numeric just for training\n",
    "labels = list(classification_labels_mapping.keys())\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=256)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pHp4kLGVgZxJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "id": "eO67ZdIBekE5",
    "outputId": "894df530-02ed-46c8-ee27-ee079b7c46c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmjm/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1200\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n",
      "  Number of trainable parameters = 592899\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-75\n",
      "Configuration saved in output/checkpoint-75/config.json\n",
      "Model weights saved in output/checkpoint-75/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-75/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-75/special_tokens_map.json\n",
      "Saving model checkpoint to output/checkpoint-150\n",
      "Configuration saved in output/checkpoint-150/config.json\n",
      "Model weights saved in output/checkpoint-150/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-150/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-150/special_tokens_map.json\n",
      "Saving model checkpoint to output/checkpoint-225\n",
      "Configuration saved in output/checkpoint-225/config.json\n",
      "Model weights saved in output/checkpoint-225/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-225/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-225/special_tokens_map.json\n",
      "Saving model checkpoint to output/checkpoint-300\n",
      "Configuration saved in output/checkpoint-300/config.json\n",
      "Model weights saved in output/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-300/special_tokens_map.json\n",
      "Saving model checkpoint to output/checkpoint-375\n",
      "Configuration saved in output/checkpoint-375/config.json\n",
      "Model weights saved in output/checkpoint-375/pytorch_model.bin\n",
      "tokenizer config file saved in output/checkpoint-375/tokenizer_config.json\n",
      "Special tokens file saved in output/checkpoint-375/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.6363027750651041, metrics={'train_runtime': 65.7439, 'train_samples_per_second': 91.263, 'train_steps_per_second': 5.704, 'total_flos': 86933280672000.0, 'train_loss': 0.6363027750651041, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a new Trainer with all the objects we constructed so far\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\", \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "xV9BpzNYhtmJ",
    "outputId": "4ff20e8d-7484-4667-a6f8-2b74191ad3b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6240424513816833,\n",
       " 'eval_accuracy': 0.7733333333333333,\n",
       " 'eval_precision': 0.7344449330000299,\n",
       " 'eval_recall': 0.6990252030782612,\n",
       " 'eval_f1': 0.7080831054324427,\n",
       " 'eval_runtime': 2.1328,\n",
       " 'eval_samples_per_second': 140.658,\n",
       " 'eval_steps_per_second': 8.908,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Model-2022-11-12 04:07:28.400454\n",
      "Configuration saved in Model-2022-11-12 04:07:28.400454/config.json\n",
      "Model weights saved in Model-2022-11-12 04:07:28.400454/pytorch_model.bin\n",
      "tokenizer config file saved in Model-2022-11-12 04:07:28.400454/tokenizer_config.json\n",
      "Special tokens file saved in Model-2022-11-12 04:07:28.400454/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "model_path = \"Model-\"+ str(datetime.now())\n",
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbO2Z6_ou6RP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 80% Acurracy, not bad! But is the evaluation metrics enough to say the model is good? üí≠\n",
    "\n",
    "\n",
    "*   What if the model is showing different prediction when you change the words from \"He\" to \"She\" ? ü§î\n",
    "\n",
    "*   What if the words like \"ain't\" which is more used by African American person is introduced in the statement, will the prediction change ? ü§î\n",
    "\n",
    "* Is the performance metrics like accuracy, F1 score changing when you change the name of the user to more feminine in your texts?\n",
    "\n",
    "* Is your model gender or race biased? ü§îü§î\n",
    "\n",
    "These are really important questions which we need to have definite answers  but due to lack of tools for testing, it is often neglected leading to serious issues in future üòü\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-Oo1G8wD0aq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## üåü Don't worry! [Giskard](https://github.com/Giskard-AI/giskard) is here to help! We are an open source Quality Assurance and CI/CD platform who empowers Data Scientists to inspect and test their model while they are creating it, enabling them to publish it on productions with confidence!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cItO7aQiRtTr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Here is a sneak peek of our test suites üòç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fxoU7zfO-j2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_test_suites.png](https://raw.githubusercontent.com/Giskard-AI/examples/main/images/giskard_tests.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF91vdtrR2w2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cant wait to explore?! Lets start with  [Installing Giskard](https://docs.giskard.ai/start/) üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8sbXBdhS9ur",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## All we need is a simple function that returns the prediction probabilities üòå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_Xa0R90auV0w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(test_dataset):\n",
    "    test_dataset= test_dataset.squeeze(axis=1)\n",
    "    X_test = list(test_dataset.apply(preprocess))\n",
    "    X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=256)\n",
    "\n",
    "    # Create torch dataset\n",
    "    test_dataset = Dataset(X_test_tokenized)\n",
    "\n",
    "    # Define test trainer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    test_trainer = Trainer(model)\n",
    "\n",
    "    # Make prediction\n",
    "    raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "    predictions = torch.nn.functional.softmax(torch.from_numpy(raw_pred), dim=-1)\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "8q2P-PT3Os1S",
    "outputId": "28dec6f9-2ca2-4805-afeb-2fef7e791b30",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Model-2022-11-12 04:07:28.400454/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"Model-2022-11-12 04:07:28.400454\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"max_length\": 64,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padding\": \"max_length\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Model-2022-11-12 04:07:28.400454/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Model-2022-11-12 04:07:28.400454.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14584884, 0.82460743, 0.02954371],\n",
       "       [0.45388135, 0.33464956, 0.21146904],\n",
       "       [0.71399975, 0.262861  , 0.02313922],\n",
       "       [0.89301366, 0.07649449, 0.03049184],\n",
       "       [0.98587877, 0.01041047, 0.00371073]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick test to verify the predict is working before uploading on Giskard\n",
    "feature_names = ['text']\n",
    "test_df = data[feature_names][:5]\n",
    "predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFvZwm4yTjkg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    \n",
    "  def predict(self, context, model_input):\n",
    "    return self.model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Model-2022-11-12 04:07:28.400454/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"Model-2022-11-12 04:07:28.400454\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"max_length\": 64,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padding\": \"max_length\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Model-2022-11-12 04:07:28.400454/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Model-2022-11-12 04:07:28.400454.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14584884, 0.82460743, 0.02954371],\n",
       "       [0.45388135, 0.33464956, 0.21146904],\n",
       "       [0.71399975, 0.262861  , 0.02313922],\n",
       "       [0.89301366, 0.07649449, 0.03049184],\n",
       "       [0.98587877, 0.01041047, 0.00371073]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelWrapper(predict).predict(None, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Model-2022-11-12 04:07:28.400454/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"Model-2022-11-12 04:07:28.400454\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"max_length\": 64,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padding\": \"max_length\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Model-2022-11-12 04:07:28.400454/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Model-2022-11-12 04:07:28.400454.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='run_sentiment') as run:\n",
    "        mlflow.log_metric('auc', 0.8)\n",
    "        mlflow.log_param('n_estimators', 100)\n",
    "        wrappedModel = ModelWrapper(predict)\n",
    "            \n",
    "        test_df = data[['text']][:5]    \n",
    "        signature = infer_signature( test_df, wrappedModel.predict(None, test_df))\n",
    "\n",
    "        mlflow.pyfunc.log_model(\"HF-model\", python_model=wrappedModel, signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/12 05:15:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2022/11/12 05:15:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e8efa2c4c0374b76bc942cd3b448be41', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators = 100, max_depth = 6, max_features = 3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)\n",
    "autolog_run = mlflow.last_active_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='param1' was already logged with value='35' for run ID='f3b3bfad8a56440a820149231be1786e'. Attempted logging new value '3'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:316\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:908\u001b[0m, in \u001b[0;36mFileStore.log_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    907\u001b[0m check_run_is_active(run_info)\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_run_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:914\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_new_param_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriteable_param_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:934\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_value \u001b[38;5;241m!=\u001b[39m new_value:\n\u001b[0;32m--> 934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChanging param values is not allowed. Param with key=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was already\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m logged with value=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for run ID=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Attempted logging new value\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(param_key, current_value, run_id, new_value),\n\u001b[1;32m    938\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    939\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='param1' was already logged with value='35' for run ID='f3b3bfad8a56440a820149231be1786e'. Attempted logging new value '3'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_metric, log_param, log_artifacts\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Log a parameter (key-value pair)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Log a metric; metrics can be updated throughout the run\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     log_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoo\u001b[39m\u001b[38;5;124m\"\u001b[39m, random())\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:542\u001b[0m, in \u001b[0;36mlog_param\u001b[0;34m(key, value)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mLog a parameter (e.g. model hyperparameter) under the current run. If no run is active,\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m        assert value == 0.01\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/tracking/client.py:876\u001b[0m, in \u001b[0;36mMlflowClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m    Log a parameter (e.g. model hyperparameter) against the run ID.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/PycharmProjects/sentiment-analysis/venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:320\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m==\u001b[39m ErrorCode\u001b[38;5;241m.\u001b[39mName(INVALID_PARAMETER_VALUE):\n\u001b[1;32m    319\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mPARAM_VALIDATION_MSG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(msg, INVALID_PARAMETER_VALUE)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='param1' was already logged with value='35' for run ID='f3b3bfad8a56440a820149231be1786e'. Attempted logging new value '3'.\n\nThe cause of this error is typically due to repeated calls\nto an individual run_id event logging.\n\nIncorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    mlflow.log_param(\"depth\", 3)\n    mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will throw an MlflowException for overwriting a\nlogged parameter.\n\nCorrect Example:\n---------------------------------------\nwith mlflow.start_run():\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 3)\n    with mlflow.start_run(nested=True):\n        mlflow.log_param(\"depth\", 5)\n---------------------------------------\n\nWhich will create a new nested run for each individual\nmodel and prevent parameter key collisions within the\ntracking store.'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Log a parameter (key-value pair)\n",
    "    log_param(\"param1\", randint(0, 100))\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    log_metric(\"foo\", random())\n",
    "    log_metric(\"foo\", random() + 1)\n",
    "    log_metric(\"foo\", random() + 2)\n",
    "\n",
    "    # Log an artifact (output file)\n",
    "    if not os.path.exists(\"outputs\"):\n",
    "        os.makedirs(\"outputs\")\n",
    "    with open(\"outputs/test.txt\", \"w\") as f:\n",
    "        f.write(\"hello world!\")\n",
    "    log_artifacts(\"outputs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFvZwm4yTjkg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Let the adventure begin ü§©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw-VIs42VgcZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from giskard import GiskardClient\n",
    "\n",
    "url = \"http://dev.giskard.ai/19000\"  # If Giskard is installed locally (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "token = \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsInRva2VuX3R5cGUiOiJBUEkiLCJhdXRoIjoiUk9MRV9BRE1JTiIsImV4cCI6MTY3NTU4MDkzNX0.RwLlZy5Yg6FQBas7nGsw68J-tJDSDGiMqYeUe6JAHcc\" # you can generate your API token in the Admin tab of the Giskard application (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "# your_project = client.create_project(\"project_key\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "# Choose the arguments you want. But \"project_key\" should be unique and in lower case\n",
    "sentiment_analysis = client.create_project(\"sentiment_analysis_jm_bis\", \"Sentimental Analysis for Twitter Data\", \"Sentimental Analysis for Twitter Data\")\n",
    "\n",
    "# If you've already created a project with the key \"sentiment_analysis\" use\n",
    "#sentiment_analysis = client.get_project(\"sentiment_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHhTzzEeWbIj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "column_types={       \n",
    "        'airline_sentiment': \"category\",\n",
    "        \"text\": \"text\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "FVxeLEaMWPzL",
    "outputId": "34db723d-02c4-46ba-d8dc-e8aaa0d07a60",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded to project key 'sentiment_analysis_jm_bis' and is available at http://dev.giskard.ai \n",
      "Model successfully uploaded to project key 'sentiment_analysis_jm_bis' and is available at http://dev.giskard.ai \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7675, 7673)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis.upload_model_and_df(\n",
    "    prediction_function=predict, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='classification', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    df=data[['text','airline_sentiment']].sample(100), # The dataset you want to use to inspect your model\n",
    "    column_types=column_types, # # A dictionary with columns names of df as key and types(category, numeric, text) of columns as values\n",
    "    target='airline_sentiment', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=['text'], # List of the feature names of prediction_function\n",
    "    model_name='sentiment_analysis', # Name of the model\n",
    "    dataset_name='twitter_airlinedata', # Name of the dataset\n",
    "    classification_labels=labels # List of the classification labels of your prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgxV_myEUFSS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hurray ü•≥ Your Dataset and model is now uploaded on Giskard and is available at http://localhost:19000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UwDVqooUlLC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Want to download real-time data? Let's start with connecting to your [twitter account using API](https://developer.twitter.com/en/docs/tutorials/step-by-step-guide-to-making-your-first-request-to-the-twitter-api-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROSYwDIMRQvp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add Twitter API key and secret\n",
    "consumer_key = \"XXX\"\n",
    "consumer_secret = \"XXX\"\n",
    "\n",
    "# Handling authentication with Twitter\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# Create a wrapper for the Twitter API\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iEyy_V3RdPv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for handling pagination in our search and handle rate limits\n",
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.RateLimitError:\n",
    "            print('Reached rate limite. Sleeping for >15 minutes')\n",
    "            time.sleep(15 * 61)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "# Define the term we will be using for searching tweets\n",
    "query = '#virginairlines'\n",
    "query = query + ' -filter:retweets'\n",
    "\n",
    "# Define how many tweets to get from the Twitter API \n",
    "count = 1000\n",
    "\n",
    "# Let's search for tweets using Tweepy \n",
    "search = limit_handled(tweepy.Cursor(api.search,\n",
    "                        q=query,\n",
    "                        tweet_mode='extended',\n",
    "                        lang='en',\n",
    "                        result_type=\"recent\").items(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuHe4FPORiDQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's retrive the important data from the search\n",
    "tweets = []\n",
    "for tweet in search:\n",
    "   try:\n",
    "     tweets.append({'id':tweet.id, 'user': tweet.user.name,'date':tweet.created_at,'text': tweet.full_text})\n",
    " \n",
    "   except:\n",
    "     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQai4wxHRlBQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data in a dataframe\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.width', 3000) \n",
    "prod_data = pd.DataFrame(tweets)\n",
    "\n",
    "prod_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqt-1Gg1ZXoN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lets upload this data on Giskard! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cdbPHdZ52KG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis.upload_df(\n",
    "    df=prod_data, # The dataset you want to upload\n",
    "    column_types=['text'], # All the column types without the target\n",
    "    name=\"production_data\" # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZgaQ3NLaYBL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Happy Exploration üïµÔ∏è‚Äç‚ôÇÔ∏è üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05431caf64ec45578e7bebcfbf8793e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06d946f52b854886bb87e6dec2d3de33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1378411b913f4543bf18f49982d1f257": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1997813f378f49babcfc2e4fd8d9bffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06d946f52b854886bb87e6dec2d3de33",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7eb657a3d2534928a1ec9d65eeede7a7",
      "value": "Downloading: 100%"
     }
    },
    "205c9112e6ec4393baf11cbb19197cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20bf1250145b4035a26f0abaeb8ad397": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "240fbc1a408a44e6b0f4ba741d4b3877": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c638db378e940be8ac9a881f3e5bcab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e2d886843104af48b43e60e08f2eaca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c0c92a04f42431c979b63cf1639c39b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b1524520f4084d24a0a7b6740412aaf4",
      "value": " 319/319 [00:00&lt;00:00, 9.27kB/s]"
     }
    },
    "30bf10b8b69444e0bdeb69a150bff90d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_597ef6c3d5714ba9b17c4b5e0c4e6298",
      "max": 826,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94841079aae14290a54e755305e1fe98",
      "value": 826
     }
    },
    "370d3a9c8c9b46ba9cc7a18d3247e4b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "433494e2cec941ca948d534f0801ccfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3dbb16958b436b87062cfcd8449e7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57cfdccea7104655894840e76dd19cf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_babe7ddacc7e41bb9e8a491c2dace6df",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_aa64b2c6ed1940e29db9cb6ac282c1ca",
      "value": " 466k/466k [00:01&lt;00:00, 510kB/s]"
     }
    },
    "597ef6c3d5714ba9b17c4b5e0c4e6298": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a65d70f73f24e45bccad44111560965": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4f8931b838f42e69c583cba079d8819",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e2963e445e04d7c976b5c8280be9409",
      "value": 112
     }
    },
    "5af3e3f57dc54a75a96c9cbd0a43d6d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1378411b913f4543bf18f49982d1f257",
      "max": 466245,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95fd39e854ec485c83445fdc79b0ec78",
      "value": 466245
     }
    },
    "5b3f6395ccce4ebe93d152cad2590ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5bbb2b62a064459da41036486d8467b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd2ef87554ee4ad5931c99eb348cb6d8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_240fbc1a408a44e6b0f4ba741d4b3877",
      "value": "Downloading: 100%"
     }
    },
    "5e2963e445e04d7c976b5c8280be9409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "619170c0b67545639fc79008be836570": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6296e3ef24c74862820a08e26a68300f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "662239855e124b55864dca725d48fe51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bbb2b62a064459da41036486d8467b6",
       "IPY_MODEL_9816bf8f2728475189e8119064e681d8",
       "IPY_MODEL_f7e9822b18fb461aab94545a9f782cf4"
      ],
      "layout": "IPY_MODEL_370d3a9c8c9b46ba9cc7a18d3247e4b5"
     }
    },
    "663b2a0bcb664c49acbca8b75846f968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68c8d063693a456fb4aebe5c05acbc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f7c4695785e4627b8f9c2fce9c124b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7543528284d48778f19e198879d6c3e",
       "IPY_MODEL_30bf10b8b69444e0bdeb69a150bff90d",
       "IPY_MODEL_9dd398a3b1bb45319c6b267d79f9fc3c"
      ],
      "layout": "IPY_MODEL_ef0d1af1abdc4184b62910289307e388"
     }
    },
    "71bc594634b24dddb7e13958eed0f8c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db451d50371f40ff94d8815b197f9e66",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_663b2a0bcb664c49acbca8b75846f968",
      "value": "Downloading: 100%"
     }
    },
    "77070a12337f4f31ae419f0c5d576ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8633c5f48eae42bea49f585a2efbf63e",
       "IPY_MODEL_5a65d70f73f24e45bccad44111560965",
       "IPY_MODEL_77c3c230ae14453981e2c12669abc6e4"
      ],
      "layout": "IPY_MODEL_c1857a9f64de4bb283cb4dc98da3a36a"
     }
    },
    "77c3c230ae14453981e2c12669abc6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f31d095b9838490f887e3d085fac6fbc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_205c9112e6ec4393baf11cbb19197cea",
      "value": " 112/112 [00:00&lt;00:00, 1.20kB/s]"
     }
    },
    "7eb657a3d2534928a1ec9d65eeede7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8633c5f48eae42bea49f585a2efbf63e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dca1c643f5ef4d2c8b634483308d22a6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b356bbd1a04e496bb35baa52216a0a7c",
      "value": "Downloading: 100%"
     }
    },
    "8c0c92a04f42431c979b63cf1639c39b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91847cc3840f4c719d8c2df8a2f02d58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92807e26f48541f19d3a96d4cc902057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b3dbb16958b436b87062cfcd8449e7f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b9bc25db3b0044d8ba47d91fb002bcb4",
      "value": "Downloading: 100%"
     }
    },
    "94841079aae14290a54e755305e1fe98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "958f20afe0974f6b935edaf21812db9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5b6ecd5eea743a2a3b51758358bddb4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f9e58cc62392447bbb6e18c8d717ce68",
      "value": " 232k/232k [00:00&lt;00:00, 240kB/s]"
     }
    },
    "95fd39e854ec485c83445fdc79b0ec78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9816bf8f2728475189e8119064e681d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_433494e2cec941ca948d534f0801ccfd",
      "max": 267863153,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68c8d063693a456fb4aebe5c05acbc42",
      "value": 267863153
     }
    },
    "9d82a182865e458c86a84890fc3fdd6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dd398a3b1bb45319c6b267d79f9fc3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c638db378e940be8ac9a881f3e5bcab",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_cac1d8002367468ca4a0099ca561396d",
      "value": " 826/826 [00:00&lt;00:00, 8.57kB/s]"
     }
    },
    "a6702f313e0444648237775fa7e75f0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1997813f378f49babcfc2e4fd8d9bffa",
       "IPY_MODEL_cf9f715ad5ef4cadab2d7a1e42eeb5fd",
       "IPY_MODEL_2e2d886843104af48b43e60e08f2eaca"
      ],
      "layout": "IPY_MODEL_91847cc3840f4c719d8c2df8a2f02d58"
     }
    },
    "aa64b2c6ed1940e29db9cb6ac282c1ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1524520f4084d24a0a7b6740412aaf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b256a26d6be741b894351ef9767b3f8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20bf1250145b4035a26f0abaeb8ad397",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b3f6395ccce4ebe93d152cad2590ae1",
      "value": 231508
     }
    },
    "b356bbd1a04e496bb35baa52216a0a7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9bc25db3b0044d8ba47d91fb002bcb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "babe7ddacc7e41bb9e8a491c2dace6df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1857a9f64de4bb283cb4dc98da3a36a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7543528284d48778f19e198879d6c3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_619170c0b67545639fc79008be836570",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_eb4de1afc71d4a7694d1cb590736f439",
      "value": "Downloading: 100%"
     }
    },
    "cac1d8002367468ca4a0099ca561396d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb9440d378f14d17a622118a2ce6463a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92807e26f48541f19d3a96d4cc902057",
       "IPY_MODEL_b256a26d6be741b894351ef9767b3f8c",
       "IPY_MODEL_958f20afe0974f6b935edaf21812db9c"
      ],
      "layout": "IPY_MODEL_05431caf64ec45578e7bebcfbf8793e9"
     }
    },
    "cbfd1bdb36aa4606995f4b7e4dc49b48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc352732f21d4a43a03b18a2bf416586": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71bc594634b24dddb7e13958eed0f8c9",
       "IPY_MODEL_5af3e3f57dc54a75a96c9cbd0a43d6d0",
       "IPY_MODEL_57cfdccea7104655894840e76dd19cf8"
      ],
      "layout": "IPY_MODEL_dc4ca8b791bc49d6a7d7c033b7122a22"
     }
    },
    "cf9f715ad5ef4cadab2d7a1e42eeb5fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d82a182865e458c86a84890fc3fdd6c",
      "max": 319,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6296e3ef24c74862820a08e26a68300f",
      "value": 319
     }
    },
    "db451d50371f40ff94d8815b197f9e66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc4ca8b791bc49d6a7d7c033b7122a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dca1c643f5ef4d2c8b634483308d22a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2ef87554ee4ad5931c99eb348cb6d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5b6ecd5eea743a2a3b51758358bddb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa558d36243448aa3f8dd9a815285bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb4de1afc71d4a7694d1cb590736f439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef0d1af1abdc4184b62910289307e388": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f31d095b9838490f887e3d085fac6fbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4f8931b838f42e69c583cba079d8819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7e9822b18fb461aab94545a9f782cf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfd1bdb36aa4606995f4b7e4dc49b48",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_eaa558d36243448aa3f8dd9a815285bf",
      "value": " 268M/268M [00:12&lt;00:00, 19.0MB/s]"
     }
    },
    "f9e58cc62392447bbb6e18c8d717ce68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
